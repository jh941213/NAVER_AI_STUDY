{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 3주차 미션 - Numpy"
      ],
      "metadata": {
        "id": "Mt-1R0YNabUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9L7_xghEagpn",
        "outputId": "b6ebbddc-406b-4e72-e21f-6303a00719e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1. 본격적으로 Numpy와 친해지기 위해서 다양한 연산을 연습해볼 예정입니다. **무작위의 데이터를 가진 5x3의 행렬을 가지는 numpy array와 3x2 행렬을 가지는 numpy array를 만든 후 행렬곱 연산**을 진행해보세요.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "arr1 = #TODO\n",
        "arr2 = #TODO\n",
        "\n",
        "dot = # TODO\n",
        "```\n",
        "```bash\n",
        "# 출력 예시\n",
        ">>> print(dot, dot.shape) # 결과 값은 달라질 수 있으나, 연산 후 shape는 일정해야 한다.\n",
        "[[0.25 1.97]\n",
        " [0.11 0.96]\n",
        " [0.50 0.37]\n",
        " [0.28 0.23]\n",
        " [0.39 0.83]] (5, 2)\n",
        "```"
      ],
      "metadata": {
        "id": "QglzmGY3aU6T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A1."
      ],
      "metadata": {
        "id": "eeys15pAgzin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 5x3 크기의 난수 어레이 생성\n",
        "arr1 = np.random.rand(5,3)\n",
        "# 3x2 크기의 난수 어레이 생성\n",
        "arr2 = np.random.rand(3,2)\n",
        "\n",
        "# Answer1\n",
        "# np.dot 함수를 사용하여 행렬곱 연산\n",
        "# 5x3 * 3x2 -> 5x2 크기의 행렬 생성\n",
        "dot = np.dot(arr1, arr2)\n",
        "\n",
        "# Answer2\n",
        "# np.matmul 함수를 사용하여 행렬곱 연산\n",
        "matmul = np.matmul(arr1, arr2)\n",
        "\n",
        "# Answer3\n",
        "# @ 연산자를 사용하여 행렬곱 연산\n",
        "mul_operator = arr1@arr2\n",
        "\n",
        "# 결과 출력\n",
        "print('[Answer 1] np.dot 연산 결과\\n', dot, dot.shape, '\\n')\n",
        "print('[Answer 2] np.matmul 연산 결과\\n', matmul, matmul.shape, '\\n')\n",
        "print('[Answer 3] @ 연산 결과\\n', mul_operator, mul_operator.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj9boLaLa0hJ",
        "outputId": "bdb8ab4c-a0ac-4248-922d-4a3643b01347"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Answer 1] np.dot 연산 결과\n",
            " [[0.67918064 0.8289918 ]\n",
            " [0.76524298 0.57636109]\n",
            " [0.83350684 0.93614632]\n",
            " [0.79505904 0.7607289 ]\n",
            " [0.95061547 1.22979121]] (5, 2) \n",
            "\n",
            "[Answer 2] np.matmul 연산 결과\n",
            " [[0.67918064 0.8289918 ]\n",
            " [0.76524298 0.57636109]\n",
            " [0.83350684 0.93614632]\n",
            " [0.79505904 0.7607289 ]\n",
            " [0.95061547 1.22979121]] (5, 2) \n",
            "\n",
            "[Answer 3] @ 연산 결과\n",
            " [[0.67918064 0.8289918 ]\n",
            " [0.76524298 0.57636109]\n",
            " [0.83350684 0.93614632]\n",
            " [0.79505904 0.7607289 ]\n",
            " [0.95061547 1.22979121]] (5, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "❗ 2차원 공간까지는 dot (내적) 연산과 행렬곱 연산(matmul, @)이 동일하나,   \n",
        "3차원 공간부터는 달라지니 주의할 것!"
      ],
      "metadata": {
        "id": "vS1UpUbBbpsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2. 두번째로는 numpy에서 자주 사용하는 concatenate 연산에 대한 미션을 수행해보겠습니다. 이제 Numpy에서 사용하는 2개의 numpy array가 있을 때, **두 numpy array의 concatenate 연산**을 구해보세요. \n",
        "- axis는 0, 1 두개로 연산한 결과를 출력해보세요.\n",
        "- 각 데이터가 어떤 형태로 더해지는지 확인해보세요.\n",
        "\n",
        "```python\n",
        "arr1 = np.array([[5, 7], [9, 11]], float)\n",
        "arr2 = np.array([[2, 4], [6, 8]], float)\n",
        "\n",
        "concat_1 = # TODO axis 0\n",
        "concat_2 = # TODO axis 1\n",
        "```\n",
        "\n",
        "```bash\n",
        "# 출력 예시\n",
        ">>>\n",
        "[[5. 7.]\n",
        " [9. 11.]\n",
        " [2. 4.]\n",
        " [6. 8.]]\n",
        "[[5. 7. 2. 4.]\n",
        " [9. 11. 6. 8.]]\n",
        "```\n"
      ],
      "metadata": {
        "id": "fOf9rZu-f2KY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A2."
      ],
      "metadata": {
        "id": "4N39OEkmgtp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2x2 크기의 실수 타입 numpy array 선언\n",
        "arr1 = np.array([[5, 7], [9, 11]], float)\n",
        "arr2 = np.array([[2, 4], [6, 8]], float)\n",
        "\n",
        "# 각각 axis 0, axis 1 방향으로 concatenation 진행\n",
        "concat_1 = np.concatenate((arr1, arr2), axis=0) # axis 0\n",
        "concat_2 = np.concatenate((arr1, arr2), axis=1) # axis 1\n",
        "\n",
        "# 결과 값 출력\n",
        "print(f'concat_1 (axis=0):\\n {concat_1}\\n')\n",
        "print(f'concat_2 (axis=1):\\n {concat_2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXT91Gfgg39A",
        "outputId": "26b359df-23c9-43d5-d752-b8158947f47b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "concat_1 (axis=0):\n",
            " [[ 5.  7.]\n",
            " [ 9. 11.]\n",
            " [ 2.  4.]\n",
            " [ 6.  8.]]\n",
            "\n",
            "concat_2 (axis=1):\n",
            " [[ 5.  7.  2.  4.]\n",
            " [ 9. 11.  6.  8.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3. 3번부터 5번까지의 미션은 Numpy를 이용해서 정답값을 예측해보는 linear regression을 구현해보는 미션입니다. 첫번째 단계로 데이터를 준비해보도록 하겠습니다. 아래와 같이 데이터가 주어져있을 때, **경사하강법을 위한 데이터를 분리**해보세요.\n",
        "- 주어진 xy 데이터를 이용해서 학습과 정답 데이터를 준비해보세요.\n",
        "- \\*추가 수정* 문제에서 주어진 xy에서 대괄호를 한 번 더 묶어주어야 문제 해결이 가능합니다.  (차원 관련) (np.array([[1., 2., 3., 4., 5., 6.], [10., 20., 30., 40., 50., 60.]])\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "xy = np.array([[1., 2., 3., 4., 5., 6.], [10., 20., 30., 40., 50., 60.]])\n",
        "x_train = # TODO\n",
        "y_train = # TODO\n",
        "```\n",
        "```bash\n",
        ">>> print(x_train, x_train.shape)\n",
        ">>> print(y_train, y_train.shape)\n",
        "[1. 2. 3. 4. 5. 6.] (6,)\n",
        "[10. 20. 30. 40. 50. 60] (6,)\n",
        "```"
      ],
      "metadata": {
        "id": "vzHkznL1hsDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A3."
      ],
      "metadata": {
        "id": "L2pm76cyir34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 주어진 xy 데이터 \n",
        "xy = np.array([[1., 2., 3., 4., 5., 6.], [10., 20., 30., 40., 50., 60.]])\n",
        "\n",
        "# training을 위한 x, y 데이터 분리\n",
        "x_train = xy[0] # 첫번째 차원의 0번 index\n",
        "y_train = xy[1] # 첫번째 차원의 1번 index\n",
        "\n",
        "# x_train, y_train 출력\n",
        "print(x_train, x_train.shape)\n",
        "print(y_train, y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f_AX3L0je_I",
        "outputId": "16f1e16c-fbde-4ccd-d374-0f59e975043a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 2. 3. 4. 5. 6.] (6,)\n",
            "[10. 20. 30. 40. 50. 60.] (6,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q4. **경사 하강법 구현을 위해서 위에서 분리한 x_train 데이터와 계산될 weight, bias 값을 정의**해보세요. 여기서 구현한 weight와 bias는 linear regression 계산을 진행할 때, 직선의 기울기와 y 절편의 값이 됩니다.\n",
        "- numpy 내의 random 함수를 이용해보세요.\n",
        "\n",
        "```python\n",
        "beta_gd = #TODO\n",
        "bias = #TODO\n",
        "```\n",
        "```bash\n",
        "# 출력 예시\n",
        ">>> print(beta_gd, bias)\n",
        "# random 값이어서 값이 다를 수 있습니다. 같은형태로 나오면 됩니다.\n",
        "[0.75373235] [0.94214468]\n",
        "```"
      ],
      "metadata": {
        "id": "kiUycPiYkJmT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A4."
      ],
      "metadata": {
        "id": "aRNC_uIUkh4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 임의의 값으로 weight, bias의 초기값 설정\n",
        "# 1차원의 numpy array 생성\n",
        "beta_gd = np.random.rand(1)\n",
        "bias = np.random.rand(1)\n",
        "\n",
        "# weight, bias 출력\n",
        "print(beta_gd, bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8ZV5d_1mZQQ",
        "outputId": "62570dcc-f48e-4ac9-c1ea-ea8f8f7be789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.12296025] [0.15985076]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q5. 이제 최종적으로 **linear regression을 경사하강법으로 학습하는 코드**를 구현해봅시다. 경사하강법 구현을 위한 학습 loop를 구현해보세요. 최종적으로 100회 반복했을 시의 결과를 출력하세요.\n",
        "- 단 Error는 차이의 제곱을 이용해서 계산해주세요.\n",
        "- Gradient 값은 우리가 예측하는 각 변수에 대한 미분값입니다.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "xy = np.array([[1., 2., 3., 4., 5., 6.],\n",
        "[3., 6., 9., 12., 15., 18.]])\n",
        "\n",
        "x_train = # Q3\n",
        "y_train = # Q3\n",
        "\n",
        "beta_gd = # Q4\n",
        "bias = # Q4\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "for i in range(1000):\n",
        "    # TODO\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print('Epoch ([:10d]/1000) error: [:10f], beta_gd [:10f], bias:[:10f]'.format(i, error, beta_gd.item(), bias.item()))\n",
        "```\n",
        "```bash\n",
        "# 출력 예시\n",
        ">>>\n",
        "Epoch (         0/1000) error: 514.645910, beta_gd   4.768506, bias:  1.761048\n",
        "Epoch (       100/1000) error:   0.023560, beta_gd   2.967780, bias:  0.139757\n",
        "Epoch (       200/1000) error:   0.000281, beta_gd   2.996436, bias:  0.015260\n",
        "Epoch (       300/1000) error:   0.000003, beta_gd   2.999611, bias:  0.001667\n",
        "Epoch (       400/1000) error:   0.000000, beta_gd   2.999957, bias:  0.000182\n",
        "Epoch (       500/1000) error:   0.000000, beta_gd   2.999995, bias:  0.000020\n",
        "Epoch (       600/1000) error:   0.000000, beta_gd   2.999999, bias:  0.000002\n",
        "Epoch (       700/1000) error:   0.000000, beta_gd   3.000000, bias:  0.000000\n",
        "Epoch (       800/1000) error:   0.000000, beta_gd   3.000000, bias:  0.000000\n",
        "Epoch (       900/1000) error:   0.000000, beta_gd   3.000000, bias:  0.000000\n",
        "```"
      ],
      "metadata": {
        "id": "FX2GmvFim8sq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A5."
      ],
      "metadata": {
        "id": "GfG18NzXoUEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 주어진 xy 좌표 array\n",
        "xy = np.array([[1., 2., 3., 4., 5., 6.],\n",
        "[3., 6., 9., 12., 15., 18.]])\n",
        "\n",
        "# Q3 - 1번째 차원의 0번 1번 index로 분리\n",
        "x_train = xy[0]\n",
        "y_train = xy[1]\n",
        "\n",
        "# Q4 - numpy random함수를 사용하여 1차원의 값으로 weight와 bias 초기화\n",
        "beta_gd = np.random.rand(1)\n",
        "bias = np.random.rand(1)\n",
        "\n",
        "# 학습률 지정\n",
        "learning_rate = 0.01\n",
        "# 학습을 위한 epoch 지정\n",
        "epoch = 1000\n",
        "\n",
        "for i in range(epoch):\n",
        "    # linear regression을 위한 경사하강법 학습 코드\n",
        "    # 정답값과 예측값 간의 error를 최소화 -> 목적식\n",
        "    # 실제 error는 제곱해서 사용, 여기서는 error를 미분했을 때의 값 {f(g(x))}' = f'(g(x))g'(x) 에서 f'(g(x))\n",
        "    error = (y_train - (x_train * beta_gd + bias))\n",
        "    # MSE(Mean Squared Error)\n",
        "    loss = np.sum(error**2)\n",
        "    # 목적식을 beta_gd, bias로 미분\n",
        "    gradient_beta = -2 * np.transpose(error) @ x_train # sum 구해주기 위해 transpose 해주고 행렬곱 연산\n",
        "    gradient_bias = -2 * np.sum(error) # 미분하면 bias가 1이되고 나머지 term은 소거됨\n",
        "\n",
        "    # 경사 하강법 적용 부분\n",
        "    beta_gd = beta_gd - learning_rate * gradient_beta \n",
        "    bias = bias - learning_rate * gradient_bias \n",
        "\n",
        "    # 100 epoch 단위로 log 출력\n",
        "    if i % 100 == 0:\n",
        "        print('Epoch ({:10d}/1000) error: {:10f}, beta_gd {:10f}, bias:{:10f}'.format(i, loss.item(), beta_gd.item(), bias.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAdyToFzoW0A",
        "outputId": "e95b50ff-b56f-428f-de33-86176b85150a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch (         0/1000) error: 514.645910, beta_gd   4.768506, bias:  1.761048\n",
            "Epoch (       100/1000) error:   0.023560, beta_gd   2.967780, bias:  0.139757\n",
            "Epoch (       200/1000) error:   0.000281, beta_gd   2.996436, bias:  0.015260\n",
            "Epoch (       300/1000) error:   0.000003, beta_gd   2.999611, bias:  0.001667\n",
            "Epoch (       400/1000) error:   0.000000, beta_gd   2.999957, bias:  0.000182\n",
            "Epoch (       500/1000) error:   0.000000, beta_gd   2.999995, bias:  0.000020\n",
            "Epoch (       600/1000) error:   0.000000, beta_gd   2.999999, bias:  0.000002\n",
            "Epoch (       700/1000) error:   0.000000, beta_gd   3.000000, bias:  0.000000\n",
            "Epoch (       800/1000) error:   0.000000, beta_gd   3.000000, bias:  0.000000\n",
            "Epoch (       900/1000) error:   0.000000, beta_gd   3.000000, bias:  0.000000\n"
          ]
        }
      ]
    }
  ]
}